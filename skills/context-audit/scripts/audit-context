#!/usr/bin/env bash
set -euo pipefail

usage() {
  cat <<'EOF'
Usage: audit-context [--session [<path>]] [--flagged] [--top <N>] [--json] [--help]

Static inventory of context-contributing sources and session token analysis.

Scans:
  ~/.claude/skills/*/SKILL.md        Size and word count
  ~/.claude/skills/*/rules/*.md      Always-on files (count)
  ~/.claude/skills/*/references/*.md On-demand files (count)
  ~/CLAUDE.md and project CLAUDE.md  Size and word count (recursive)
  ~/.claude/projects/*/memory/*.md   Auto-memory files
  ~/.claude/settings.json            Plugins, MCP servers, and tool counts

Session analysis (--session):
  Parses JSONL to extract per-turn token usage, context growth,
  top spikes, cache hit rates, and preceding tool calls.
  Requires jq.

Options:
  --session [<path>]  Include session token analysis. Auto-detects
                      most recent JSONL if no path given.
  --flagged           Only show items with flags (LARGE, RULES, MCP)
  --top <N>           Number of top spikes to show (default: 5).
                      Also limits inventory entries by size.
  --json              Output as JSON
  --help              Show this help message

Exit codes:
  0  Success
  1  ~/.claude/skills/ not found
  2  --session requires jq but jq is not installed
  3  --session specified but no JSONL found
EOF
}

JSON_OUTPUT=false
DO_SESSION=false
SESSION_PATH=""
FLAGGED_ONLY=false
TOP_N=0

while [[ $# -gt 0 ]]; do
  case "$1" in
    --json) JSON_OUTPUT=true; shift ;;
    --flagged) FLAGGED_ONLY=true; shift ;;
    --top) TOP_N="$2"; shift 2 ;;
    --session)
      DO_SESSION=true
      shift
      # Next arg is optional path (not another flag)
      if [[ $# -gt 0 && "$1" != --* ]]; then
        SESSION_PATH="$1"; shift
      fi
      ;;
    --help) usage; exit 0 ;;
    *) echo "Unknown option: $1" >&2; usage >&2; exit 1 ;;
  esac
done

SKILLS_DIR="$HOME/.claude/skills"

if [[ ! -d "$SKILLS_DIR" ]]; then
  # shellcheck disable=SC2088  # tilde in user-facing message is intentional
  echo "~/.claude/skills/ not found" >&2
  exit 1
fi

# Helper: get file size in bytes (portable)
file_size() {
  wc -c < "$1" | tr -d ' '
}

# Helper: get word count
word_count() {
  wc -w < "$1" | tr -d ' '
}

# Helper: format bytes for display
format_size() {
  local bytes=$1
  if [[ $bytes -ge 1024 ]]; then
    echo "$(( (bytes + 512) / 1024 ))KB"
  else
    echo "${bytes}B"
  fi
}

# ── Static Inventory ─────────────────────────────────────────────

# Collect entries as tab-separated: source \t size_bytes \t words \t loads \t flag
entries=()

# Scan SKILL.md files
for skill_dir in "$SKILLS_DIR"/*/; do
  [[ -d "$skill_dir" ]] || continue
  skill_name=$(basename "$skill_dir")

  skill_file="$skill_dir/SKILL.md"
  if [[ -f "$skill_file" ]]; then
    s=$(file_size "$skill_file")
    w=$(word_count "$skill_file")
    flag="-"
    [[ $w -gt 500 ]] && flag="LARGE"
    entries+=("skills/$skill_name/SKILL.md	$s	$w	on-trigger	$flag")
  fi

  rules_dir="$skill_dir/rules"
  if [[ -d "$rules_dir" ]]; then
    for rule_file in "$rules_dir"/*.md; do
      [[ -f "$rule_file" ]] || continue
      rule_name=$(basename "$rule_file")
      s=$(file_size "$rule_file")
      w=$(word_count "$rule_file")
      entries+=("skills/$skill_name/rules/$rule_name	$s	$w	always-on	RULES")
    done
  fi

  refs_dir="$skill_dir/references"
  if [[ -d "$refs_dir" ]]; then
    for ref_file in "$refs_dir"/*.md; do
      [[ -f "$ref_file" ]] || continue
      ref_name=$(basename "$ref_file")
      s=$(file_size "$ref_file")
      w=$(word_count "$ref_file")
      entries+=("skills/$skill_name/references/$ref_name	$s	$w	on-demand	-")
    done
  fi
done

# CLAUDE.md files — global
if [[ -f "$HOME/CLAUDE.md" ]]; then
  s=$(file_size "$HOME/CLAUDE.md")
  w=$(word_count "$HOME/CLAUDE.md")
  flag="-"
  [[ $s -gt 2048 ]] && flag="LARGE"
  entries+=("CLAUDE.md (global)	$s	$w	always-on	$flag")
fi

# CLAUDE.md files — project root and subdirectories
# Discover all CLAUDE.md files under cwd (depth 3 max) excluding home dir
if [[ "$(pwd)" != "$HOME" ]]; then
  while IFS= read -r claude_file; do
    [[ -z "$claude_file" ]] && continue
    rel_path="${claude_file#"$(pwd)"/}"
    s=$(file_size "$claude_file")
    w=$(word_count "$claude_file")
    flag="-"
    [[ $s -gt 2048 ]] && flag="LARGE"
    if [[ "$rel_path" == "CLAUDE.md" ]]; then
      entries+=("CLAUDE.md (project)	$s	$w	always-on	$flag")
    else
      entries+=("$rel_path	$s	$w	always-on	$flag")
    fi
  done < <(find "$(pwd)" -maxdepth 3 -name "CLAUDE.md" -type f 2>/dev/null)
fi

# Auto-memory files
for mem_dir in "$HOME"/.claude/projects/*/memory/; do
  [[ -d "$mem_dir" ]] || continue
  project_hash=$(basename "$(dirname "$mem_dir")")
  for mem_file in "$mem_dir"*.md; do
    [[ -f "$mem_file" ]] || continue
    mem_name=$(basename "$mem_file")
    s=$(file_size "$mem_file")
    w=$(word_count "$mem_file")
    flag="-"
    [[ $w -gt 300 ]] && flag="LARGE"
    # Shorten project hash for display
    short_hash="${project_hash:0:20}"
    entries+=("memory/${short_hash}…/$mem_name	$s	$w	always-on	$flag")
  done
done

# Settings: plugins and MCP servers
SETTINGS_FILE="$HOME/.claude/settings.json"
plugin_count=0
mcp_count=0
plugin_names=()
if [[ -f "$SETTINGS_FILE" ]]; then
  # Count enabled plugins from enabledPlugins object
  if command -v jq &>/dev/null; then
    plugin_count=$(jq '[.enabledPlugins // {} | to_entries[] | select(.value == true)] | length' "$SETTINGS_FILE" 2>/dev/null || echo 0)
    while IFS= read -r pname; do
      [[ -n "$pname" ]] && plugin_names+=("$pname")
    done < <(jq -r '.enabledPlugins // {} | to_entries[] | select(.value == true) | .key | split("@")[0]' "$SETTINGS_FILE" 2>/dev/null)
    mcp_count=$(jq '.mcpServers // {} | keys | length' "$SETTINGS_FILE" 2>/dev/null || echo 0)
  else
    plugin_count=$(grep -c '@' "$SETTINGS_FILE" 2>/dev/null || true)
    plugin_count=${plugin_count:-0}
    mcp_count=$(sed -n '/"mcpServers"/,/^  }/p' "$SETTINGS_FILE" 2>/dev/null | grep -c '"[^"]*":' || true)
    mcp_count=${mcp_count:-0}
  fi
  flag="-"
  [[ $mcp_count -ge 5 ]] && flag="MCP"
  entries+=("settings.json (${plugin_count} plugins, ${mcp_count} MCP)	0	0	always-on	$flag")

  # Add per-plugin entries with estimated tool counts
  # Known tool counts for common plugins (tool descriptions always loaded)
  for pname in "${plugin_names[@]}"; do
    tool_est=2  # default estimate
    case "$pname" in
      playwright) tool_est=22 ;;
      context7) tool_est=2 ;;
      hookify) tool_est=5 ;;
      commit-commands) tool_est=4 ;;
      claude-code-setup) tool_est=2 ;;
      claude-md-management) tool_est=2 ;;
    esac
    pflag="-"
    [[ $tool_est -ge 10 ]] && pflag="HEAVY"
    entries+=("plugin: $pname (~${tool_est} tools)	0	$((tool_est * 50))	always-on	$pflag")
  done
fi

# Sort entries by size descending
sorted=()
while IFS= read -r line; do
  sorted+=("$line")
done < <(for e in "${entries[@]}"; do echo "$e"; done | sort -t$'\t' -k2 -rn)

# Compute totals
total_always_on_words=0
total_trigger_words=0
trigger_count=0

for entry in "${sorted[@]}"; do
  IFS=$'\t' read -r source size words loads flag <<< "$entry"
  case "$loads" in
    always-on)
      total_always_on_words=$((total_always_on_words + words))
      ;;
    on-trigger)
      total_trigger_words=$((total_trigger_words + words))
      trigger_count=$((trigger_count + 1))
      ;;
  esac
done

avg_trigger_words=0
[[ $trigger_count -gt 0 ]] && avg_trigger_words=$((total_trigger_words / trigger_count))

total_always_on_words=$((total_always_on_words + mcp_count * 200 + plugin_count * 50))

# Apply filters to create display list
display=()
count=0
for entry in "${sorted[@]}"; do
  IFS=$'\t' read -r source size words loads flag <<< "$entry"

  if [[ "$FLAGGED_ONLY" == true && "$flag" == "-" ]]; then
    continue
  fi

  display+=("$entry")
  count=$((count + 1))

  if [[ $TOP_N -gt 0 && $count -ge $TOP_N ]]; then
    break
  fi
done

filtered_count=${#display[@]}
total_count=${#sorted[@]}

# ── Session Token Analysis ───────────────────────────────────────

session_turns=0
session_start=0
session_current=0
session_growth_rate=0
session_cache_hit_pct=0
session_json=""
SPIKE_COUNT="${TOP_N:-5}"
[[ "$SPIKE_COUNT" -eq 0 ]] && SPIKE_COUNT=5

if [[ "$DO_SESSION" == true ]]; then
  if ! command -v jq &>/dev/null; then
    echo "Error: --session requires jq but jq is not installed" >&2
    exit 2
  fi

  # Auto-detect session JSONL if not provided
  if [[ -z "$SESSION_PATH" ]]; then
    # shellcheck disable=SC2012  # ls -t needed for time-sorted output
    SESSION_PATH=$(ls -t "$HOME"/.claude/projects/*/*.jsonl 2>/dev/null | head -1 || true)
  fi

  if [[ -n "$SESSION_PATH" && -f "$SESSION_PATH" ]]; then
    # jq script: extract assistant turns with usage + preceding tool calls
    # Produces one JSON object per assistant turn with token stats and
    # the last tool_use name/input from the prior content blocks.
    jq_err=$(mktemp)
    session_json=$(jq -c -s --argjson top "$SPIKE_COUNT" '
      # Collect assistant messages with usage data
      # Support both top-level .usage and .message.usage layouts
      [ .[] | select(.type == "assistant")
            | . + { _usage: (.message.usage // .usage // null) }
            | select(._usage | (. == null) | not)
      ] as $turns |

      # Build per-turn records with preceding tool info
      [ $turns | to_entries[] | {
        idx: .key,
        input: (.value._usage.input_tokens // 0),
        cache_create: (.value._usage.cache_creation_input_tokens // 0),
        cache_read: (.value._usage.cache_read_input_tokens // 0),
        total: ((.value._usage.input_tokens // 0)
              + (.value._usage.cache_creation_input_tokens // 0)
              + (.value._usage.cache_read_input_tokens // 0)),
        tool: (
          [ (.value.message.content // [])[]
            | select(.type == "tool_use") ]
          | last
          | if . then {name: .name, args: (.input | tostring | .[:80])} else null end
        )
      }] as $records |

      # Aggregate stats
      ($records | length) as $count |
      ($records | first.total // 0) as $start |
      ($records | last.total // 0) as $current |
      (if $count > 1 then (($current - $start) / ($count - 1) | floor) else 0 end) as $growth |

      # Cache hit percentage across all turns
      ([$records[].cache_read] | add // 0) as $cr_sum |
      ([$records[].total] | add // 0) as $t_sum |
      (if $t_sum > 0 then ($cr_sum * 100 / $t_sum | floor) else 0 end) as $cache_pct |

      # Compute deltas and find top spikes
      [ $records | to_entries[]
        | select(.key > 0)
        | {
            turn: (.value.idx + 1),
            delta: (.value.total - ($records[.key - 1].total)),
            total: .value.total,
            preceding_tool: (
              $records[.key - 1].tool.name // $records[.key].tool.name // "-"
            ),
            tool_args_summary: (
              $records[.key - 1].tool.args // $records[.key].tool.args // ""
            )
          }
      ] | sort_by(-.delta) | .[:$top] | map(. + {abs_delta: (if .delta < 0 then -.delta else .delta end)})
        | sort_by(-.abs_delta) as $spikes |

      {
        turns: $count,
        start_tokens: $start,
        current_tokens: $current,
        growth_per_turn: $growth,
        cache_hit_pct: $cache_pct,
        spikes: $spikes
      }
    ' "$SESSION_PATH" 2>"$jq_err")
    jq_status=$?
    if [[ $jq_status -ne 0 ]]; then
      echo "Warning: jq failed (exit $jq_status) parsing session JSONL: $(cat "$jq_err")" >&2
      session_json=""
    fi
    rm -f "$jq_err"

    if [[ -n "$session_json" && "$session_json" != "null" ]]; then
      session_turns=$(echo "$session_json" | jq '.turns')
      session_start=$(echo "$session_json" | jq '.start_tokens')
      session_current=$(echo "$session_json" | jq '.current_tokens')
      session_growth_rate=$(echo "$session_json" | jq '.growth_per_turn')
      session_cache_hit_pct=$(echo "$session_json" | jq '.cache_hit_pct')
    fi
  else
    echo "Error: no session JSONL found" >&2
    exit 3
  fi
fi

# ── Output ───────────────────────────────────────────────────────

if [[ "$JSON_OUTPUT" == true ]]; then
  echo "{"
  echo '  "inventory": ['
  first=true
  for entry in "${display[@]}"; do
    IFS=$'\t' read -r source size words loads flag <<< "$entry"
    [[ "$first" == true ]] && first=false || echo ","
    printf '    {"source": "%s", "size_bytes": %s, "words": %s, "loads": "%s", "flag": "%s"}' \
      "$source" "$size" "$words" "$loads" "$flag"
  done
  echo ""
  echo "  ],"
  printf '  "showing": %d, "total_entries": %d,' "$filtered_count" "$total_count"
  echo ""
  printf '  "totals": {"always_on_words": %d, "avg_trigger_words": %d, "skills": %d, "plugins": %d, "mcp_servers": %d}' \
    "$total_always_on_words" "$avg_trigger_words" "$trigger_count" "$plugin_count" "$mcp_count"

  if [[ "$DO_SESSION" == true && $session_turns -gt 0 ]]; then
    echo ","
    printf '  "session": %s' "$session_json"
    echo ""
  fi
  echo ""
  echo "}"
else
  # Markdown table
  if [[ $filtered_count -lt $total_count ]]; then
    echo "Showing $filtered_count of $total_count entries"
    echo ""
  fi

  printf "| %-50s | %7s | %5s | %-10s | %5s |\n" "Source" "Size" "Words" "Loads" "Flag"
  printf "|%-52s|%9s|%7s|%-12s|%7s|\n" "$(printf '%0.s-' {1..52})" "$(printf '%0.s-' {1..9})" "$(printf '%0.s-' {1..7})" "$(printf '%0.s-' {1..12})" "$(printf '%0.s-' {1..7})"

  for entry in "${display[@]}"; do
    IFS=$'\t' read -r source size words loads flag <<< "$entry"
    printf "| %-50s | %7s | %5s | %-10s | %5s |\n" "$source" "$(format_size "$size")" "$words" "$loads" "$flag"
  done

  echo ""
  echo "Totals:"
  echo "  Always-on context: ~${total_always_on_words} words (includes MCP/plugin overhead estimate)"
  echo "  Avg on-trigger cost: ~${avg_trigger_words} words per skill invocation"
  echo "  Skills: $trigger_count | Plugins: $plugin_count | MCP servers: $mcp_count"

  if [[ "$DO_SESSION" == true && $session_turns -gt 0 ]]; then
    echo ""
    echo "Session Analysis:"
    echo "  Turns: $session_turns"
    echo "  Starting context: ${session_start} tokens"
    echo "  Current context: ${session_current} tokens"
    echo "  Growth rate: ~${session_growth_rate} tokens/turn"
    echo "  Cache hit rate: ${session_cache_hit_pct}%"
    echo ""
    echo "Top Context Spikes:"
    echo "$session_json" | jq -r '.spikes | to_entries[] | "\(.key + 1). Turn \(.value.turn): \(if .value.delta >= 0 then "+\(.value.delta)" else "\(.value.delta)" end) tokens (total: \(.value.total)) — \(.value.preceding_tool)"'
  fi
fi
